{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c6f10c98-0681-479a-9297-63977f20f894","showTitle":false,"title":""}},"source":["Use the following Azure Databricks storage setup block only if you are using Azure Databricks. You can refer to the instructions here to get started:\n","https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/adls-gen2/azure-datalake-gen2-sp-access\n","\n","If you are using Synapse Spark and if your data is residing on the storage attached to the Synapse Spark workspace, you can skip the below storage setup section."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"de7ed935-dcba-42f0-a9e7-89f33dc9a494","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.functions import col\n","\n","# Load data from Event Hub using Spark\n","df = spark.readStream \\\n","    .format(\"eventhubs\") \\\n","    .option(\"eventhubs.connectionString\", \"<YourEventHubConnectionString>\") \\\n","    .option(\"eventhubs.partitionCount\", \"8\") \\\n","    .option(\"eventhubs.consumerGroup\", \"$Default\") \\\n","    .load()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e607f0b9-89b2-4f2b-9912-2e12f83dc56e","showTitle":false,"title":""}},"outputs":[],"source":["# Assuming the incoming data has a column 'sensorId' which is used as a partition key\n","partitionColumn = \"sensorId\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Add a column 'partitionKey' that will be used for partitioning in the output Event Hub\n","df_with_partition = df.withColumn(\"partitionKey\", col(partitionColumn))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write data to partitions based on the 'partitionKey'\n","query = df_with_partition.writeStream \\\n","    .format(\"eventhubs\") \\\n","    .option(\"eventhubs.connectionString\", \"<YourOutputEventHubConnectionString>\") \\\n","    .option(\"eventhubs.partitionKey\", col(\"partitionKey\")) \\\n","    .outputMode(\"update\") \\\n","    .option(\"checkpointLocation\", \"/path/to/checkpoint/dir\") \\\n","    .start()\n","\n","query.awaitTermination()"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"DataPruningWithSpark-C2","notebookOrigID":188113580888522,"widgets":{}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"save_output":true,"synapse_widget":{"state":{},"version":"0.1"}},"nbformat":4,"nbformat_minor":0}
